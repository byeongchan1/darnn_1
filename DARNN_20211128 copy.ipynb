{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './DARNN_20211128_run/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 import\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')\n",
    "#os.chdir('/content/gdrive/MyDrive/python/python_dong/data_axis_transform1')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#!pip install torchmetrics\n",
    "import torchmetrics\n",
    "\n",
    "#!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path 지정\n",
    "raw_data_path = './data/stocknet-dataset/price/raw'\n",
    "\n",
    "if 'stocknet' in raw_data_path:\n",
    "    tra_date = '2014-01-02'\n",
    "    val_date = '2015-08-03'\n",
    "    tes_date = '2015-10-01'\n",
    "    end_date = '2015-12-31'\n",
    "elif 'kdd17' in raw_data_path:\n",
    "    tra_date = '2007-01-03'\n",
    "    val_date = '2015-01-02'\n",
    "    tes_date = '2016-01-04'\n",
    "    end_date = '2016-12-31'\n",
    "else:\n",
    "    print('unexpected path: %s' % raw_data_path)\n",
    "\n",
    "# os.path.isfile : 파일이 있는지 없는 지 체크\n",
    "# os.path.join(data_path, fname) : 폴더 디렉터리와 fname(stockname.csv) 붙임\n",
    "fnames = [fname for fname in os.listdir(raw_data_path) if\n",
    "            os.path.isfile(os.path.join(raw_data_path,fname))]\n",
    "\n",
    "COLUMNS_FEATURE_DATA_V1 = ['open_close_ratio', 'high_close_ratio', \n",
    "                           'low_close_ratio', 'close_lastclose_ratio', \n",
    "                           'adjclose_lastadjclose_ratio', 'close_ma5_ratio', \n",
    "                           'close_ma10_ratio', 'close_ma15_ratio', 'close_ma20_ratio', \n",
    "                           'close_ma25_ratio', 'close_ma30_ratio']\n",
    "\n",
    "ver = 'v1' # ver in ['v1', 'v2']\n",
    "if ver == 'v1':\n",
    "    COLUMNS_FEATURE = COLUMNS_FEATURE_DATA_V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [5,10,15,20,25,30]\n",
    "\n",
    "def preprocess(df, windows):\n",
    "   '''\n",
    "   전처리 함수 역할 : 전체 feature생성하여 df column에 추가\n",
    "   '''\n",
    "   data = df\n",
    "   data['open_close_ratio'] = data['Open'] / data['Close'] - 1\n",
    "   data['high_close_ratio'] = data['High'] / data['Close'] - 1\n",
    "   data['low_close_ratio'] = data['Low'] / data['Close'] - 1\n",
    "\n",
    "   data['close_lastclose_ratio'] = np.zeros(len(data))\n",
    "   data.loc[1:, 'close_lastclose_ratio'] = data['Close'][1:].values / data['Close'][:-1].values - 1\n",
    "\n",
    "   data['adjclose_lastadjclose_ratio'] = np.zeros(len(data))\n",
    "   data.loc[1:, 'adjclose_lastadjclose_ratio'] = data['Adj Close'][1:].values / data['Adj Close'][:-1].values - 1\n",
    "\n",
    "   for window in windows:\n",
    "      data[f'close_ma{window}_ratio'] = data['Adj Close'].rolling(window).mean()/data['Adj Close'] - 1\n",
    "   \n",
    "   data['label'] = np.append((data['Close'][1:].values > data['Close'][:-1].values)*1,0)\n",
    "\n",
    "   return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_path = './data/stocknet-dataset/price/feature'\n",
    "\n",
    "for fname in fnames:\n",
    "   if not os.path.isfile(os.path.join(feature_data_path,fname)):\n",
    "      df_raw = pd.read_csv(os.path.join(raw_data_path,fname))\n",
    "      data = preprocess(df_raw, windows)\n",
    "\n",
    "      # 폴더 없으면 생성\n",
    "      try:\n",
    "         if not os.path.exists(feature_data_path):\n",
    "            os.makedirs(feature_data_path)\n",
    "      except OSError:\n",
    "         print ('Error: Creating directory. ' +  feature_data_path)\n",
    "\n",
    "      #csv 파일 저장\n",
    "      data.to_csv(os.path.join(feature_data_path,fname))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ticker : AAPL.csv, date check : True\n",
      "ticker : ABB.csv, date check : True\n",
      "ticker : ABBV.csv, date check : True\n",
      "ticker : AEP.csv, date check : True\n",
      "ticker : AGFS.csv, date check : False\n",
      "ticker : AMGN.csv, date check : True\n",
      "ticker : AMZN.csv, date check : True\n",
      "ticker : BA.csv, date check : True\n",
      "ticker : BABA.csv, date check : False\n",
      "ticker : BAC.csv, date check : True\n",
      "ticker : BBL.csv, date check : True\n",
      "ticker : BCH.csv, date check : True\n",
      "ticker : BHP.csv, date check : True\n",
      "ticker : BP.csv, date check : True\n",
      "ticker : BRK-A.csv, date check : True\n",
      "ticker : BSAC.csv, date check : True\n",
      "ticker : BUD.csv, date check : True\n",
      "ticker : C.csv, date check : True\n",
      "ticker : CAT.csv, date check : True\n",
      "ticker : CELG.csv, date check : True\n",
      "ticker : CHL.csv, date check : True\n",
      "ticker : CHTR.csv, date check : True\n",
      "ticker : CMCSA.csv, date check : True\n",
      "ticker : CODI.csv, date check : True\n",
      "ticker : CSCO.csv, date check : True\n",
      "ticker : CVX.csv, date check : True\n",
      "ticker : D.csv, date check : True\n",
      "ticker : DHR.csv, date check : True\n",
      "ticker : DIS.csv, date check : True\n",
      "ticker : DUK.csv, date check : True\n",
      "ticker : EXC.csv, date check : True\n",
      "ticker : FB.csv, date check : True\n",
      "ticker : GD.csv, date check : True\n",
      "ticker : GE.csv, date check : True\n",
      "ticker : GOOG.csv, date check : True\n",
      "ticker : HD.csv, date check : True\n",
      "ticker : HON.csv, date check : True\n",
      "ticker : HRG.csv, date check : True\n",
      "ticker : HSBC.csv, date check : True\n",
      "ticker : IEP.csv, date check : True\n",
      "ticker : INTC.csv, date check : True\n",
      "ticker : JNJ.csv, date check : True\n",
      "ticker : JPM.csv, date check : True\n",
      "ticker : KO.csv, date check : True\n",
      "ticker : LMT.csv, date check : True\n",
      "ticker : MA.csv, date check : True\n",
      "ticker : MCD.csv, date check : True\n",
      "ticker : MDT.csv, date check : True\n",
      "ticker : MMM.csv, date check : True\n",
      "ticker : MO.csv, date check : True\n",
      "ticker : MRK.csv, date check : True\n",
      "ticker : MSFT.csv, date check : True\n",
      "ticker : NEE.csv, date check : True\n",
      "ticker : NGG.csv, date check : True\n",
      "ticker : NVS.csv, date check : True\n",
      "ticker : ORCL.csv, date check : True\n",
      "ticker : PCG.csv, date check : True\n",
      "ticker : PCLN.csv, date check : True\n",
      "ticker : PEP.csv, date check : True\n",
      "ticker : PFE.csv, date check : True\n",
      "ticker : PG.csv, date check : True\n",
      "ticker : PICO.csv, date check : True\n",
      "ticker : PM.csv, date check : True\n",
      "ticker : PPL.csv, date check : True\n",
      "ticker : PTR.csv, date check : True\n",
      "ticker : RDS-B.csv, date check : True\n",
      "ticker : REX.csv, date check : True\n",
      "ticker : SLB.csv, date check : True\n",
      "ticker : SNP.csv, date check : True\n",
      "ticker : SNY.csv, date check : True\n",
      "ticker : SO.csv, date check : True\n",
      "ticker : SPLP.csv, date check : True\n",
      "ticker : SRE.csv, date check : True\n",
      "ticker : T.csv, date check : True\n",
      "ticker : TM.csv, date check : True\n",
      "ticker : TOT.csv, date check : True\n",
      "ticker : TSM.csv, date check : True\n",
      "ticker : UL.csv, date check : True\n",
      "ticker : UN.csv, date check : True\n",
      "ticker : UNH.csv, date check : True\n",
      "ticker : UPS.csv, date check : True\n",
      "ticker : UTX.csv, date check : True\n",
      "ticker : V.csv, date check : True\n",
      "ticker : VZ.csv, date check : True\n",
      "ticker : WFC.csv, date check : True\n",
      "ticker : WMT.csv, date check : True\n",
      "ticker : XOM.csv, date check : True\n",
      "87 87\n",
      "fail_cnt : 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 마지막에 index 종목 넣기\\nraw_data_index_path = './data/stocknet-dataset/price/raw/index'\\n\\nfname = os.listdir(raw_data_index_path)[0]\\n\\ndf = pd.read_csv(os.path.join(raw_data_index_path,fname))\\ndata = preprocess(df, windows)\\n\\nlearning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\\ntra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\\ntra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['adjclose_lastadjclose_ratio']\\n#tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\\n\\nval_data_X_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\\nval_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['adjclose_lastadjclose_ratio']\\n#val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label']\\n\\ntest_data_X_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\\ntest_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['adjclose_lastadjclose_ratio']\\n#test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\\n\\nprint('ticker : {}, date check : {}'.format(fname, np.array_equal(target_dates.values, learning_data.values)))\\nif np.array_equal(target_dates.values, learning_data.values):\\n    \\n    tra_data_X.append(tra_data_X_ticker.values)\\n    # tra_data_Y.append(tra_data_Y_ticker.values)\\n\\n    val_data_X.append(val_data_X_ticker.values)\\n    # val_data_Y.append(val_data_Y_ticker.values)\\n    \\n    test_data_X.append(test_data_X_ticker.values)\\n    # test_data_Y.append(test_data_Y_ticker.values)\\n\\n    tickers.append(fname)\\n\\n# tra_data_X\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_path = './data/stocknet-dataset/price/raw'\n",
    "\n",
    "\n",
    "tra_data_X = []\n",
    "tra_data_Y = []\n",
    "val_data_X = []\n",
    "val_data_Y = []\n",
    "test_data_X = []\n",
    "test_data_Y = []\n",
    "tickers = []\n",
    "\n",
    "cnt = 0\n",
    "fail_cnt = 0\n",
    "\n",
    "fnames = [fname for fname in os.listdir(raw_data_path) if\n",
    "            os.path.isfile(os.path.join(raw_data_path,fname))]\n",
    "\n",
    "for fname in fnames:\n",
    "\n",
    "    df = pd.read_csv(os.path.join(raw_data_path,fname))\n",
    "    data = preprocess(df, windows)\n",
    "\n",
    "    learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\n",
    "    tra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
    "    tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['adjclose_lastadjclose_ratio']\n",
    "    #tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\n",
    "\n",
    "    val_data_X_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\n",
    "    val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['adjclose_lastadjclose_ratio']\n",
    "    #val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label'] \n",
    "\n",
    "    test_data_X_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\n",
    "    test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['adjclose_lastadjclose_ratio']\n",
    "    #test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\n",
    "\n",
    "\n",
    "    if cnt == 0:\n",
    "        # 첫 티커의 learining_data는 학습 date를 갖는 array\n",
    "        # 첫 티커의 학습 date를 target_dates로 두고, 다음 티커들은 target_dates와 대조\n",
    "        # 학습 date가 같으면 학습data에 추가, 아니면 추가하지않음\n",
    "        # 학습 date가 같으면 vali, test date도 같은걸로 가정\n",
    "        target_dates = learning_data\n",
    "    \n",
    "    print('ticker : {}, date check : {}'.format(fname, np.array_equal(target_dates.values, learning_data.values)))\n",
    "    #print('X_null data count : train {}, val {}, test {}'\n",
    "    #    .format(tra_data_X_ticker.head().isnull().sum().sum(), val_data_X_ticker.head().isnull().sum().sum(), test_data_X_ticker.head().isnull().sum().sum()))\n",
    "    #print('y_null data count : train {}, val {}, test {}'\n",
    "    #    .format(tra_data_Y_ticker.head().isnull().sum().sum(), val_data_Y_ticker.head().isnull().sum().sum(), test_data_Y_ticker.head().isnull().sum().sum()))\n",
    "        \n",
    "    if np.array_equal(target_dates.values, learning_data.values): \n",
    "        \n",
    "        tra_data_X.append(tra_data_X_ticker.values)\n",
    "        tra_data_Y.append(tra_data_Y_ticker.values)\n",
    "\n",
    "        val_data_X.append(val_data_X_ticker.values)\n",
    "        val_data_Y.append(val_data_Y_ticker.values)\n",
    "        \n",
    "        test_data_X.append(test_data_X_ticker.values)\n",
    "        test_data_Y.append(test_data_Y_ticker.values)\n",
    "\n",
    "        tickers.append(fname)\n",
    "    else : \n",
    "        fail_cnt += 1\n",
    "    \n",
    "    cnt += 1\n",
    "\n",
    "print(cnt, len(fnames))\n",
    "print('fail_cnt :', fail_cnt)\n",
    "\n",
    "'''\n",
    "# 마지막에 index 종목 넣기\n",
    "raw_data_index_path = './data/stocknet-dataset/price/raw/index'\n",
    "\n",
    "fname = os.listdir(raw_data_index_path)[0]\n",
    "\n",
    "df = pd.read_csv(os.path.join(raw_data_index_path,fname))\n",
    "data = preprocess(df, windows)\n",
    "\n",
    "learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\n",
    "tra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
    "tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['adjclose_lastadjclose_ratio']\n",
    "#tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['label']\n",
    "\n",
    "val_data_X_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)][COLUMNS_FEATURE]\n",
    "val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['adjclose_lastadjclose_ratio']\n",
    "#val_data_Y_ticker = data[(data['Date'] >= val_date) & (data['Date'] < tes_date)]['label']\n",
    "\n",
    "test_data_X_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)][COLUMNS_FEATURE]\n",
    "test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['adjclose_lastadjclose_ratio']\n",
    "#test_data_Y_ticker = data[(data['Date'] >= tes_date) & (data['Date'] <= end_date)]['label']\n",
    "\n",
    "print('ticker : {}, date check : {}'.format(fname, np.array_equal(target_dates.values, learning_data.values)))\n",
    "if np.array_equal(target_dates.values, learning_data.values):\n",
    "    \n",
    "    tra_data_X.append(tra_data_X_ticker.values)\n",
    "    # tra_data_Y.append(tra_data_Y_ticker.values)\n",
    "\n",
    "    val_data_X.append(val_data_X_ticker.values)\n",
    "    # val_data_Y.append(val_data_Y_ticker.values)\n",
    "    \n",
    "    test_data_X.append(test_data_X_ticker.values)\n",
    "    # test_data_Y.append(test_data_Y_ticker.values)\n",
    "\n",
    "    tickers.append(fname)\n",
    "\n",
    "# tra_data_X\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_tensor(list_):\n",
    "    return torch.Tensor(np.array(list_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_tra_data_X = list_to_tensor(tra_data_X)\n",
    "tensor_tra_data_Y = list_to_tensor(tra_data_Y).view((len(tra_data_Y),-1,1))\n",
    "tensor_val_data_X = list_to_tensor(val_data_X)\n",
    "tensor_val_data_Y = list_to_tensor(val_data_Y).view((len(val_data_Y),-1,1))\n",
    "tensor_test_data_X = list_to_tensor(test_data_X)\n",
    "tensor_test_data_Y = list_to_tensor(test_data_Y).view((len(test_data_Y),-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"encoder in DA_RNN.\"\"\"\n",
    "\n",
    "    def __init__(self, T,\n",
    "                 input_size,\n",
    "                 encoder_num_hidden,\n",
    "                 parallel=False):\n",
    "        \"\"\"Initialize an encoder in DA_RNN.\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder_num_hidden = encoder_num_hidden\n",
    "        self.input_size = input_size\n",
    "        self.parallel = parallel\n",
    "        self.T = T\n",
    "\n",
    "        # Fig 1. Temporal Attention Mechanism: Encoder is LSTM\n",
    "        self.encoder_lstm = nn.LSTM(\n",
    "            input_size=self.input_size,\n",
    "            hidden_size=self.encoder_num_hidden,\n",
    "            num_layers = 1\n",
    "        )\n",
    "\n",
    "        # Construct Input Attention Mechanism via deterministic attention model\n",
    "        # Eq. 8: W_e[h_{t-1}; s_{t-1}] + U_e * x^k\n",
    "        self.encoder_attn = nn.Linear(\n",
    "            in_features=2 * self.encoder_num_hidden + self.T - 1,\n",
    "            out_features=1\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"forward.\n",
    "\n",
    "        Args:\n",
    "            X: input data\n",
    "\n",
    "        \"\"\"\n",
    "        X_tilde = Variable(X.data.new(\n",
    "            X.size(0), self.T - 1, self.input_size).zero_())\n",
    "        X_encoded = Variable(X.data.new(\n",
    "            X.size(0), self.T - 1, self.encoder_num_hidden).zero_())\n",
    "\n",
    "        # Eq. 8, parameters not in nn.Linear but to be learnt\n",
    "        # v_e = torch.nn.Parameter(data=torch.empty(\n",
    "        #     self.input_size, self.T).uniform_(0, 1), requires_grad=True)\n",
    "        # U_e = torch.nn.Parameter(data=torch.empty(\n",
    "        #     self.T, self.T).uniform_(0, 1), requires_grad=True)\n",
    "\n",
    "        # h_n, s_n: initial states with dimention hidden_size\n",
    "        h_n = self._init_states(X)\n",
    "        s_n = self._init_states(X)\n",
    "\n",
    "        for t in range(self.T - 1):\n",
    "            # batch_size * input_size * (2 * hidden_size + T - 1)\n",
    "            x = torch.cat((h_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           s_n.repeat(self.input_size, 1, 1).permute(1, 0, 2),\n",
    "                           X.permute(0, 2, 1)), dim=2)\n",
    "\n",
    "            x = self.encoder_attn(\n",
    "                x.view(-1, self.encoder_num_hidden * 2 + self.T - 1))\n",
    "\n",
    "            # get weights by softmax\n",
    "            alpha = F.softmax(x.view(-1, self.input_size), dim=1)\n",
    "\n",
    "            # get new input for LSTM\n",
    "            x_tilde = torch.mul(alpha, X[:, t, :])\n",
    "\n",
    "            # Fix the warning about non-contiguous memory\n",
    "            # https://discuss.pytorch.org/t/dataparallel-issue-with-flatten-parameter/8282\n",
    "            self.encoder_lstm.flatten_parameters()\n",
    "\n",
    "            # encoder LSTM\n",
    "            _, final_state = self.encoder_lstm(x_tilde.unsqueeze(0), (h_n, s_n))\n",
    "            h_n = final_state[0]\n",
    "            s_n = final_state[1]\n",
    "\n",
    "            X_tilde[:, t, :] = x_tilde\n",
    "            X_encoded[:, t, :] = h_n\n",
    "\n",
    "        return X_tilde, X_encoded\n",
    "\n",
    "    def _init_states(self, X):\n",
    "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
    "\n",
    "        Args:\n",
    "            X\n",
    "\n",
    "        Returns:\n",
    "            initial_hidden_states\n",
    "        \"\"\"\n",
    "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
    "        return Variable(X.data.new(1, X.size(0), self.encoder_num_hidden).zero_())\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"decoder in DA_RNN.\"\"\"\n",
    "\n",
    "    def __init__(self, T, decoder_num_hidden, encoder_num_hidden):\n",
    "        \"\"\"Initialize a decoder in DA_RNN.\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder_num_hidden = decoder_num_hidden\n",
    "        self.encoder_num_hidden = encoder_num_hidden\n",
    "        self.T = T\n",
    "\n",
    "        self.attn_layer = nn.Sequential(\n",
    "            nn.Linear(2 * decoder_num_hidden + encoder_num_hidden, encoder_num_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(encoder_num_hidden, 1)\n",
    "        )\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=decoder_num_hidden\n",
    "        )\n",
    "        self.fc = nn.Linear(encoder_num_hidden + 1, 1)\n",
    "        self.fc_final = nn.Linear(decoder_num_hidden + encoder_num_hidden, 1)\n",
    "\n",
    "        self.fc.weight.data.normal_()\n",
    "\n",
    "    def forward(self, X_encoded, y_prev):\n",
    "        \"\"\"forward.\"\"\"\n",
    "        d_n = self._init_states(X_encoded)\n",
    "        c_n = self._init_states(X_encoded)\n",
    "\n",
    "        for t in range(self.T - 1):\n",
    "\n",
    "            x = torch.cat((d_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
    "                           c_n.repeat(self.T - 1, 1, 1).permute(1, 0, 2),\n",
    "                           X_encoded), dim=2)\n",
    "\n",
    "            beta = F.softmax(self.attn_layer(\n",
    "                x.view(-1, 2 * self.decoder_num_hidden + self.encoder_num_hidden)).view(-1, self.T - 1), dim=1)\n",
    "\n",
    "            # Eqn. 14: compute context vector\n",
    "            # batch_size * encoder_hidden_size\n",
    "            context = torch.bmm(beta.unsqueeze(1), X_encoded)[:, 0, :]\n",
    "            if t < self.T - 1:\n",
    "                # Eqn. 15\n",
    "                # batch_size * 1\n",
    "                y_tilde = self.fc(\n",
    "                    torch.cat((context, y_prev[:, t].unsqueeze(1)), dim=1))\n",
    "\n",
    "                # Eqn. 16: LSTM\n",
    "                self.lstm_layer.flatten_parameters()\n",
    "                _, final_states = self.lstm_layer(\n",
    "                    y_tilde.unsqueeze(0), (d_n, c_n))\n",
    "\n",
    "                d_n = final_states[0]  # 1 * batch_size * decoder_num_hidden\n",
    "                c_n = final_states[1]  # 1 * batch_size * decoder_num_hidden\n",
    "\n",
    "        # Eqn. 22: final output\n",
    "        y_pred = self.fc_final(torch.cat((d_n[0], context), dim=1))\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def _init_states(self, X):\n",
    "        \"\"\"Initialize all 0 hidden states and cell states for encoder.\n",
    "\n",
    "        Args:\n",
    "            X\n",
    "        Returns:\n",
    "            initial_hidden_states\n",
    "\n",
    "        \"\"\"\n",
    "        # hidden state and cell state [num_layers*num_directions, batch_size, hidden_size]\n",
    "        # https://pytorch.org/docs/master/nn.html?#lstm\n",
    "        return Variable(X.data.new(1, X.size(0), self.decoder_num_hidden).zero_())\n",
    "\n",
    "\n",
    "class DA_rnn(nn.Module):\n",
    "    \"\"\"da_rnn.\"\"\"\n",
    "\n",
    "    def __init__(self, X, y, T,\n",
    "                 encoder_num_hidden,\n",
    "                 decoder_num_hidden,\n",
    "                 batch_size,\n",
    "                 learning_rate,\n",
    "                 epochs,\n",
    "                 parallel=False):\n",
    "        \"\"\"da_rnn initialization.\"\"\"\n",
    "        super(DA_rnn, self).__init__()\n",
    "        self.encoder_num_hidden = encoder_num_hidden\n",
    "        self.decoder_num_hidden = decoder_num_hidden\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.parallel = parallel\n",
    "        self.shuffle = False\n",
    "        self.epochs = epochs\n",
    "        self.T = T\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        print(\"==> Use accelerator: \", self.device)\n",
    "\n",
    "        self.Encoder = Encoder(input_size=X.shape[1],\n",
    "                               encoder_num_hidden=encoder_num_hidden,\n",
    "                               T=T).to(self.device)\n",
    "        self.Decoder = Decoder(encoder_num_hidden=encoder_num_hidden,\n",
    "                               decoder_num_hidden=decoder_num_hidden,\n",
    "                               T=T).to(self.device)\n",
    "\n",
    "        # Loss function\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "        if self.parallel:\n",
    "            self.encoder = nn.DataParallel(self.encoder)\n",
    "            self.decoder = nn.DataParallel(self.decoder)\n",
    "\n",
    "        self.encoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
    "                                                          self.Encoder.parameters()),\n",
    "                                            lr=self.learning_rate)\n",
    "        self.decoder_optimizer = optim.Adam(params=filter(lambda p: p.requires_grad,\n",
    "                                                          self.Decoder.parameters()),\n",
    "                                            lr=self.learning_rate)\n",
    "\n",
    "        # Training set\n",
    "        self.train_timesteps = int(self.X.shape[0] * 0.7)\n",
    "        self.y = self.y - np.mean(self.y[:self.train_timesteps])\n",
    "        self.input_size = self.X.shape[1]\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"training process.\"\"\"\n",
    "        iter_per_epoch = int(np.ceil(self.train_timesteps * 1. / self.batch_size))\n",
    "        self.iter_losses = np.zeros(self.epochs * iter_per_epoch)\n",
    "        self.epoch_losses = np.zeros(self.epochs)\n",
    "\n",
    "        n_iter = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if self.shuffle:\n",
    "                ref_idx = np.random.permutation(self.train_timesteps - self.T)\n",
    "            else:\n",
    "                ref_idx = np.array(range(self.train_timesteps - self.T))\n",
    "\n",
    "            idx = 0\n",
    "\n",
    "            while (idx < self.train_timesteps):\n",
    "                # get the indices of X_train\n",
    "                indices = ref_idx[idx:(idx + self.batch_size)]\n",
    "                # x = np.zeros((self.T - 1, len(indices), self.input_size))\n",
    "                x = np.zeros((len(indices), self.T - 1, self.input_size))\n",
    "                y_prev = np.zeros((len(indices), self.T - 1))\n",
    "                y_gt = self.y[indices + self.T]\n",
    "\n",
    "                # format x into 3D tensor\n",
    "                for bs in range(len(indices)):\n",
    "                    x[bs, :, :] = self.X[indices[bs]:(indices[bs] + self.T - 1), :]\n",
    "                    y_prev[bs, :] = self.y[indices[bs]: (indices[bs] + self.T - 1)]\n",
    "\n",
    "                loss = self.train_forward(x, y_prev, y_gt)\n",
    "                self.iter_losses[int(epoch * iter_per_epoch + idx / self.batch_size)] = loss\n",
    "\n",
    "                idx += self.batch_size\n",
    "                n_iter += 1\n",
    "\n",
    "                if n_iter % 10000 == 0 and n_iter != 0:\n",
    "                    for param_group in self.encoder_optimizer.param_groups:\n",
    "                        param_group['lr'] = param_group['lr'] * 0.9\n",
    "                    for param_group in self.decoder_optimizer.param_groups:\n",
    "                        param_group['lr'] = param_group['lr'] * 0.9\n",
    "\n",
    "                self.epoch_losses[epoch] = np.mean(self.iter_losses[range(\n",
    "                    epoch * iter_per_epoch, (epoch + 1) * iter_per_epoch)])\n",
    "\n",
    "            if epoch % 500 == 0:\n",
    "                print(\"Epochs: \", epoch, \" Iterations: \", n_iter,\n",
    "                      \" Loss: \", self.epoch_losses[epoch])\n",
    "\n",
    "            if epoch % 10000 == 0:\n",
    "                y_train_pred = self.test(on_train=True)\n",
    "                y_test_pred = self.test(on_train=False)\n",
    "                y_pred = np.concatenate((y_train_pred, y_test_pred))\n",
    "                plt.ioff()\n",
    "                plt.figure()\n",
    "                plt.plot(range(1, 1 + len(self.y)), self.y, label=\"True\")\n",
    "                plt.plot(range(self.T, len(y_train_pred) + self.T),\n",
    "                         y_train_pred, label='Predicted - Train')\n",
    "                plt.plot(range(self.T + len(y_train_pred), len(self.y) + 1),\n",
    "                         y_test_pred, label='Predicted - Test')\n",
    "                plt.legend(loc='upper left')\n",
    "                plt.show()\n",
    "\n",
    "            # # Save files in last iterations\n",
    "            # if epoch == self.epochs - 1:\n",
    "            #     np.savetxt('../loss.txt', np.array(self.epoch_losses), delimiter=',')\n",
    "            #     np.savetxt('../y_pred.txt',\n",
    "            #                np.array(self.y_pred), delimiter=',')\n",
    "            #     np.savetxt('../y_true.txt',\n",
    "            #                np.array(self.y_true), delimiter=',')\n",
    "\n",
    "    def train_forward(self, X, y_prev, y_gt):\n",
    "        \"\"\"\n",
    "        Forward pass.\n",
    "\n",
    "        Args:\n",
    "            X:\n",
    "            y_prev:\n",
    "            y_gt: Ground truth label\n",
    "\n",
    "        \"\"\"\n",
    "        # zero gradients\n",
    "        self.encoder_optimizer.zero_grad()\n",
    "        self.decoder_optimizer.zero_grad()\n",
    "\n",
    "        input_weighted, input_encoded = self.Encoder(\n",
    "            Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
    "        y_pred = self.Decoder(input_encoded, Variable(\n",
    "            torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n",
    "\n",
    "        y_true = Variable(torch.from_numpy(\n",
    "            y_gt).type(torch.FloatTensor).to(self.device))\n",
    "\n",
    "        y_true = y_true.view(-1, 1)\n",
    "        loss = self.criterion(y_pred, y_true)\n",
    "        loss.backward()\n",
    "\n",
    "        self.encoder_optimizer.step()\n",
    "        self.decoder_optimizer.step()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "\n",
    "    def test(self, on_train=False):\n",
    "        \"\"\"test.\"\"\"\n",
    "\n",
    "        if on_train:\n",
    "            y_pred = np.zeros(self.train_timesteps - self.T + 1)\n",
    "        else:\n",
    "            y_pred = np.zeros(self.X.shape[0] - self.train_timesteps)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(y_pred):\n",
    "            batch_idx = np.array(range(len(y_pred)))[i: (i + self.batch_size)]\n",
    "            X = np.zeros((len(batch_idx), self.T - 1, self.X.shape[1]))\n",
    "            y_history = np.zeros((len(batch_idx), self.T - 1))\n",
    "\n",
    "            for j in range(len(batch_idx)):\n",
    "                if on_train:\n",
    "                    X[j, :, :] = self.X[range(\n",
    "                        batch_idx[j], batch_idx[j] + self.T - 1), :]\n",
    "                    y_history[j, :] = self.y[range(\n",
    "                        batch_idx[j], batch_idx[j] + self.T - 1)]\n",
    "                else:\n",
    "                    X[j, :, :] = self.X[range(\n",
    "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1), :]\n",
    "                    y_history[j, :] = self.y[range(\n",
    "                        batch_idx[j] + self.train_timesteps - self.T, batch_idx[j] + self.train_timesteps - 1)]\n",
    "\n",
    "            y_history = Variable(torch.from_numpy(\n",
    "                y_history).type(torch.FloatTensor).to(self.device))\n",
    "            _, input_encoded = self.Encoder(\n",
    "                Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n",
    "            y_pred[i:(i + self.batch_size)] = self.Decoder(input_encoded,\n",
    "                                                           y_history).cpu().data.numpy()[:, 0]\n",
    "            i += self.batch_size\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Initialize DA-RNN_0 model ...\n",
      "==> Use accelerator:  cpu\n",
      "==> Start training ...\n",
      "Epochs:  0  Iterations:  3  Loss:  0.0005812736829587569\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  10  Iterations:  33  Loss:  0.0002879906678572297\n",
      "Epochs:  20  Iterations:  63  Loss:  0.000292962315143086\n",
      "Epochs:  30  Iterations:  93  Loss:  0.00029130809707567096\n",
      "Epochs:  40  Iterations:  123  Loss:  0.0002911081683123484\n",
      "Epochs:  50  Iterations:  153  Loss:  0.00029101490023701143\n",
      "Epochs:  60  Iterations:  183  Loss:  0.0002909148655210932\n",
      "Epochs:  70  Iterations:  213  Loss:  0.0002908366489767407\n",
      "Epochs:  80  Iterations:  243  Loss:  0.0002907524079394837\n",
      "Epochs:  90  Iterations:  273  Loss:  0.00029065879061818123\n",
      "Epochs:  100  Iterations:  303  Loss:  0.00029055091727059335\n",
      "Epochs:  110  Iterations:  333  Loss:  0.0002904241652383159\n",
      "Epochs:  120  Iterations:  363  Loss:  0.0002902737711944307\n",
      "Epochs:  130  Iterations:  393  Loss:  0.0002900948068903138\n",
      "Epochs:  140  Iterations:  423  Loss:  0.00028988179595520097\n",
      "Epochs:  150  Iterations:  453  Loss:  0.00028962810756638646\n",
      "Epochs:  160  Iterations:  483  Loss:  0.0002893243363359943\n",
      "Epochs:  170  Iterations:  513  Loss:  0.00028895752135819447\n",
      "Epochs:  180  Iterations:  543  Loss:  0.00028850923020703095\n",
      "Epochs:  190  Iterations:  573  Loss:  0.0002879548022368302\n",
      "Epochs:  200  Iterations:  603  Loss:  0.0002872658660635352\n",
      "Epochs:  210  Iterations:  633  Loss:  0.0002864185905006404\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-32b38655b282>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"==> Start training ...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-cf1c513c39a5>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m                     \u001b[0my_prev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_prev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miter_losses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miter_per_epoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-cf1c513c39a5>\u001b[0m in \u001b[0;36mtrain_forward\u001b[1;34m(self, X, y_prev, y_gt)\u001b[0m\n\u001b[0;32m    312\u001b[0m             Variable(torch.from_numpy(X).type(torch.FloatTensor).to(self.device)))\n\u001b[0;32m    313\u001b[0m         y_pred = self.Decoder(input_encoded, Variable(\n\u001b[1;32m--> 314\u001b[1;33m             torch.from_numpy(y_prev).type(torch.FloatTensor).to(self.device)))\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         y_true = Variable(torch.from_numpy(\n",
      "\u001b[1;32mC:\\pyvenv\\venv36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-cf1c513c39a5>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X_encoded, y_prev)\u001b[0m\n\u001b[0;32m    149\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m                 _, final_states = self.lstm_layer(\n\u001b[1;32m--> 151\u001b[1;33m                     y_tilde.unsqueeze(0), (d_n, c_n))\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0md_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# 1 * batch_size * decoder_num_hidden\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pyvenv\\venv36\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\pyvenv\\venv36\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 680\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    681\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batchsize = 128\n",
    "nhidden_encoder = 128\n",
    "nhidden_decoder = 128\n",
    "ntimestep = 10\n",
    "lr = 0.001\n",
    "epochs = 10000\n",
    "\n",
    "# 폴더 없으면 생성\n",
    "try:\n",
    "    if not os.path.exists(file_name):\n",
    "        os.makedirs(file_name)\n",
    "except OSError:\n",
    "    print ('Error: Creating directory. ' +  file_name)\n",
    "\n",
    "y_preds = np.array([]) # numpy array로 해야 transpose 가능할것 같습니다.\n",
    "for ticker_idx in range(len(tickers)):\n",
    "    \n",
    "    X = tra_data_X[ticker_idx]\n",
    "    y = tra_data_Y[ticker_idx]\n",
    "\n",
    "    # Initialize model\n",
    "    print(\"==> Initialize DA-RNN_{} model ...\".format(ticker_idx))\n",
    "    globals()['model_{}'.format(ticker_idx)] = DA_rnn(\n",
    "        X,\n",
    "        y,\n",
    "        ntimestep,\n",
    "        nhidden_encoder,\n",
    "        nhidden_decoder,\n",
    "        batchsize,\n",
    "        lr,\n",
    "        epochs\n",
    "    )\n",
    "\n",
    "    model = globals()['model_{}'.format(ticker_idx)]\n",
    "\n",
    "    # Train\n",
    "    print(\"==> Start training ...\")\n",
    "    model.train()\n",
    "\n",
    "    # Prediction\n",
    "    y_pred = model.test()\n",
    "    globals()['y_pred_{}'.format(ticker_idx)] = y_pred\n",
    "\n",
    "    # y_pred_{ticker_idx} save to csv\n",
    "    np.savetxt(file_name+'y_pred_{}.csv'.format(ticker_idx), y_pred, delimiter=',')\n",
    "\n",
    "    # y_preds에 ticker_idx별 y_pred 저장하기\n",
    "    if ticker_idx == 0 :\n",
    "        y_preds = np.hstack((y_preds, y_pred))\n",
    "    \n",
    "    else :\n",
    "        y_preds = np.vstack((y_preds, y_pred))\n",
    "\n",
    "\n",
    "    fig1 = plt.figure()\n",
    "    plt.semilogy(range(len(model.iter_losses)), model.iter_losses)\n",
    "    plt.savefig(file_name+\"iter_losses_{}_{}.png\".format(tickers[ticker_idx],ticker_idx))\n",
    "    plt.close(fig1)\n",
    "\n",
    "    fig2 = plt.figure()\n",
    "    plt.semilogy(range(len(model.epoch_losses)), model.epoch_losses)\n",
    "    plt.savefig(file_name+\"epoch_losses_{}_{}.png\".format(tickers[ticker_idx],ticker_idx))\n",
    "    plt.close(fig2)\n",
    "\n",
    "    fig3 = plt.figure()\n",
    "    plt.plot(y_pred, label='Predicted')\n",
    "    plt.plot(model.y[model.train_timesteps:], label=\"True\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.savefig(file_name+\"test_y_{}_{}.png\".format(tickers[ticker_idx],ticker_idx))\n",
    "    plt.close(fig3)\n",
    "    print('Finished Training')\n",
    "\n",
    "np.savetxt(file_name+'y_preds.csv', y_preds, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_y_cum_return = [1]\n",
    "# 시간대별로 선택된 ticker_idx들의 실제 y값 매치한후, 누적수익률 구함\n",
    "for t in range(int(tensor_tra_data_Y[:,model.train_timesteps:,0].shape[1])):\n",
    "    # t시점의 선택된 ticker_idx들\n",
    "    indices = torch.Tensor(y_preds).topk(3,dim=0)[1][:,t]\n",
    "    select_y_cum_return.append(select_y_cum_return[t] * (1 + tensor_tra_data_Y[:,model.train_timesteps:,0][indices, t].sum()/3))\n",
    "\n",
    "# 위 시점에서 index의 cum_return_rate 구해보자\n",
    "raw_data_index_path = './data/stocknet-dataset/price/raw/index'\n",
    "\n",
    "fname = os.listdir(raw_data_index_path)[0]\n",
    "\n",
    "df = pd.read_csv(os.path.join(raw_data_index_path,fname))\n",
    "data = preprocess(df, windows)\n",
    "\n",
    "learning_data = data[(data['Date'] >= tra_date) & (data['Date'] <= end_date)]['Date']\n",
    "# tra_data_X_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)][COLUMNS_FEATURE]\n",
    "tra_data_Y_ticker = data[(data['Date'] >= tra_date) & (data['Date'] < val_date)]['adjclose_lastadjclose_ratio']\n",
    "\n",
    "\n",
    "index_cum_return = [1]\n",
    "for t in range(int(tensor_tra_data_Y[:,model.train_timesteps:,0].shape[1])):\n",
    "    index_cum_return.append(index_cum_return[t] * (1 + tra_data_Y_ticker.values[model.train_timesteps:][t]))\n",
    "\n",
    "plt.plot(range(len(select_y_cum_return)), select_y_cum_return, label='portfolio')\n",
    "plt.plot(range(len(index_cum_return)), index_cum_return, label='index')\n",
    "plt.legend()\n",
    "plt.savefig(file_name+\"cum_return_rate_epochs{}.png\".format(epochs))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0867f69e5b16c2da0a94f2a308042fc4e0db7f5095985c82e39af55064218631"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('venv36': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
